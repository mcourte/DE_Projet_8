# üå¶Ô∏è Pipeline ETL : R√©f√©rentiel Stations M√©t√©o (Projet 8)

Ce projet automatise l'extraction, la transformation et le stockage du r√©f√©rentiel des stations m√©t√©o d'InfoClimat. Le pipeline assure la transition des donn√©es depuis une source brute (Google Drive) vers une base de donn√©es NoSQL (MongoDB) via un transit s√©curis√© sur AWS S3.

## üèóÔ∏è Architecture & Logique de Migration

Le processus suit une architecture **ETL** (Extract, Transform, Load) structur√©e :



### 1. Extraction (Source vers S3)
* **Source** : Fichier `referentiel_stations.jsonl` sur Google Drive.
* **Transport** : Synchronisation via **Airbyte** vers un bucket **AWS S3** (format CSV).
* **Formatage** : Les donn√©es sont extraites de la colonne brute `_airbyte_data`.

### 2. Transformation (Python & Pandas)
Le script `transform_and_load.py` effectue les op√©rations suivantes :
* **Nettoyage (Data Quality)** : Sur les 1157 lignes initiales, le script identifie et supprime les doublons.
* **Filtrage m√©tier** : Seules les **4 stations de r√©f√©rence** sont conserv√©es (√©limination du bruit de mesures temporelles).
* **Validation** : V√©rification de la pr√©sence des colonnes critiques (`id`, `name`, `latitude`, `longitude`).

### 3. Stockage & R√©plication (MongoDB)
* **CRUD** : Le script impl√©mente les op√©rations de cr√©ation, lecture et mise √† jour.
* **R√©plication** : Les donn√©es sont stock√©es sur un **Replica Set** (3 n≈ìuds via MongoDB Atlas ou config `--replSet`), garantissant la haute disponibilit√© et la tol√©rance aux pannes.

---

## üöÄ Fonctionnement du Script

### Installation
```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Ex√©cution du PipelineBash
```
python3 transform_and_load.py
```

### G√©n√©ration du Rapport Final
```
python3 export_to_json.py
```

## üìä Mesure de la Qualit√© (Post-Migration)


| M√©trique | Valeur | Commentaire |
| :--- | :--- | :--- |
| **Lignes extraites (Raw)** | 1157 | Donn√©es brutes issues de S3 |
| **Stations valid√©es** | 4 | Apr√®s filtrage et d√©doublonnage |
| **Taux d'erreur/rejet** | 99.65% | Filtrage cibl√© pour isoler le r√©f√©rentiel |
| **Statut final** | ‚úÖ Succ√®s | Migration conforme au sch√©ma cible |

## üõ†Ô∏è Logigramme du Processus
**D√©but**: Lancement du script Python.
**Entr√©e** : R√©cup√©ration du CSV sur AWS S3 via ```boto3```.
**Traitement** : Extraction JSON et nettoyage via ```pandas```.
**D√©cision** : Test d'int√©grit√© (Doublons/Nulls).
**Stockage** : ```insert_many``` vers MongoDB (Replica Set).
**Fin** : G√©n√©ration du JSON de rendu.

## üìù Rapport Final : rendu_final_stations.json

Exemple du contenu attendu apr√®s ex√©cution de ton script d'export.

```
[
    {
        "Weather Station ID": "07015",
        "Station Name": "Lille-Lesquin",
        "Latitude / Longitude": "50.57¬∞ N, 3.09¬∞ E",
        "Elevation": "47",
        "City": "Lille",
        "State": "-/-",
        "Hardware": "other",
        "Software": "EasyWeatherPro_V5.1.6"
    }
]
```